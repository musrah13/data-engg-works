{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hacker News Data Exploration\n",
    "\n",
    "Hacker News is a site started by the startup incubator [Y Combinator](https://www.ycombinator.com/), where user-submitted stories (known as \"posts\") are voted and commented upon, similar to reddit. Hacker News is extremely popular in technology and startup circles, and posts that make it to the top of Hacker News' listings can get hundreds of thousands of visitors as a result. In this project, we are going to explore a dataset containing Hacker News data.\n",
    "\n",
    "The data set can be found [here](https://www.kaggle.com/hacker-news/hacker-news-posts), but note that it has been reduced from almost 300,000 rows to approximately 20,000 rows by removing all submissions that did not receive any comments, and then randomly sampling from the remaining submissions. Below are descriptions of the columns:\n",
    "\n",
    "- `id`: The unique identifier from Hacker News for the post\n",
    "- `title`: The title of the post\n",
    "- `url`: The URL that the posts links to, if it the post has a URL\n",
    "- `num_points`: The number of points the post acquired, calculated as the total number of upvotes minus the total number of downvotes\n",
    "- `num_comments`: The number of comments that were made on the post\n",
    "- `author`: The username of the person who submitted the post\n",
    "- `created_at`: The date and time at which the post was submitted\n",
    "\n",
    "We're specifically interested in posts whose titles begin with either `\"Ask HN\"` or `\"Show HN\"` substring. Users submit `\"Ask HN\"` posts to ask the Hacker News community a specific question. Likewise, users submit `\"Show HN\"` posts to show the Hacker News community a project, product, or just generally something interesting.\n",
    "\n",
    "We'll compare these two types of posts to determine the following:\n",
    "\n",
    "- Do `\"Ask HN\"` or `\"Show HN\"` posts receive more comments on average?\n",
    "- Do posts created at a certain time receive more comments on average?\n",
    "- Whether `\"Ask HN\"` or `\"Show HN\"` posts receive more points on average.\n",
    "- Whether posts created at a certain time are more likely to receive more points.\n",
    "\n",
    "We can also compare our results from the above 2 types posts to the average number of comments and points other posts receive.\n",
    "\n",
    "Let's start by importing the libraries we need and reading the data set into a list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "\n",
      "['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52']\n",
      "\n",
      "\n",
      "['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30']\n",
      "\n",
      "\n",
      "['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20']\n",
      "\n",
      "\n",
      "['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']\n",
      "\n",
      "\n",
      "['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "\n",
    "opened_file = open('dataset/hacker_news.csv')\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)\n",
    "headers = hn[0]\n",
    "hn = hn[1:]\n",
    "\n",
    "print(headers)\n",
    "print(\"\\n\")\n",
    "for each_row in hn[:5]:\n",
    "    print(each_row)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've removed the headers from `hn`, we're ready to filter our data. Since we're only concerned with post titles beginning with `\"Ask HN\"` or `\"Show HN\"`, we'll create new lists of lists containing just the data for those titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of posts asking ('Ask HN'): 1744\n",
      "Number of posts showing ('Show HN'): 1162\n",
      "Number of other posts: 17194\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for each_row in hn:\n",
    "    title = each_row[1].lower()\n",
    "    if title.startswith('ask hn'):\n",
    "        ask_posts.append(each_row)\n",
    "    elif title.startswith('show hn'):\n",
    "        show_posts.append(each_row)\n",
    "    else:\n",
    "        other_posts.append(each_row)\n",
    "        \n",
    "print(\"Number of posts asking ('Ask HN'): \" + str(len(ask_posts)))\n",
    "print(\"Number of posts showing ('Show HN'): \" + str(len(show_posts)))\n",
    "print(\"Number of other posts: \" + str(len(other_posts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's determine if ask posts or show posts receive more comments on average.\n",
    "\n",
    "We can create a function `avg_no_of()` as there will be redundant line of codes otherwise as we will essentially be doing the same thing (finding average number of comments for certain type of posts). `avg_no_of()` takes a list of lists (rows for `\"Ask HN\"` or `\"Show HN\"` posts from the dataset) as the first parameter and as the second parameeter it takes the index of the column for which we are going to find the average of (in this case index `4` which is the index of `num_comments` column in the dataset). It then counts the total number of comments in that certain types of posts and returns the average number of comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average comments for posts asking ('Ask HN'): 14.04\n",
      "Average comments for posts showing ('Show HN'): 10.32\n"
     ]
    }
   ],
   "source": [
    "def avg_no_of(rows, col):\n",
    "    total = 0\n",
    "    for each_row in rows:\n",
    "        n_cmnt = int(each_row[col])\n",
    "        total += n_cmnt\n",
    "        \n",
    "    avg = total/len(rows)\n",
    "    return avg\n",
    "\n",
    "avg_ask_comments = avg_no_of(ask_posts, 4)\n",
    "avg_show_comments = avg_no_of(show_posts, 4)\n",
    "\n",
    "print(\"Average comments for posts asking ('Ask HN'): \" + str(round(avg_ask_comments, 2)))\n",
    "print(\"Average comments for posts showing ('Show HN'): \" + str(round(avg_show_comments,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking from the above data, it is clear that `\"Ask HN\"` posts receive more comments on average (**14.04**) than `\"Show HN\"` posts (**10.32**).\n",
    "\n",
    "Since ask posts are more likely to receive comments, we'll focus our remaining analysis just on these posts. Next, we'll determine if ask posts created at a certain *time* are more likely to attract comments. We'll use the following steps to perform this analysis:\n",
    "\n",
    "1. Calculate the amount of ask posts created in each hour of the day, along with the number of comments received.\n",
    "\n",
    "2. Calculate the average number of comments ask posts receive by hour created.\n",
    "\n",
    "As we are going to be working with time, we can import the `datetime` module in our next script below. Then we find out the number of `\"Ask HN\"` posts by hour and save it in the variable `counts_by_hour`. Also, we find out the number of `\"Ask HN\"` posts' comments by hour and save it in the variable `comments_by_hour`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "\n",
    "for each_row in ask_posts:\n",
    "    temp_list = [each_row[6], int(each_row[4])]\n",
    "    result_list.append(temp_list)\n",
    "    \n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "for elem in result_list:\n",
    "    dt_obj = dt.datetime.strptime(elem[0], \"%m/%d/%Y %H:%M\")\n",
    "    hour = dt_obj.strftime(\"%H\")\n",
    "    if hour not in counts_by_hour:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = elem[1]\n",
    "    else:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += elem[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know hour-wise number of posts and comments for `\"Ask HN\"`, we can print out to see the distribution. It will be easier for us to take a look at this distribution if they are sorted by the total number in a descending order. \n",
    "\n",
    "Below, we create a function `print_sorted_dict_by_val_desc()` that takes a dictionary as parameter and prints the data of the dictionary in a descending order (by its value). This function can be used to help us interpret the data inside `counts_by_hour` and `comments_by_hour` more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of posts by hour [High->Low]: \n",
      "15: 116\n",
      "19: 110\n",
      "21: 109\n",
      "18: 109\n",
      "16: 108\n",
      "14: 107\n",
      "17: 100\n",
      "13: 85\n",
      "20: 80\n",
      "12: 73\n",
      "22: 71\n",
      "23: 68\n",
      "01: 60\n",
      "10: 59\n",
      "11: 58\n",
      "02: 58\n",
      "00: 55\n",
      "03: 54\n",
      "08: 48\n",
      "04: 47\n",
      "05: 46\n",
      "09: 45\n",
      "06: 44\n",
      "07: 34\n",
      "\n",
      "\n",
      "Number of comments by hour [High->Low]: \n",
      "15: 4477\n",
      "16: 1814\n",
      "21: 1745\n",
      "20: 1722\n",
      "18: 1439\n",
      "14: 1416\n",
      "02: 1381\n",
      "13: 1253\n",
      "19: 1188\n",
      "17: 1146\n",
      "10: 793\n",
      "12: 687\n",
      "01: 683\n",
      "11: 641\n",
      "23: 543\n",
      "08: 492\n",
      "22: 479\n",
      "05: 464\n",
      "00: 447\n",
      "03: 421\n",
      "06: 397\n",
      "04: 337\n",
      "07: 267\n",
      "09: 251\n"
     ]
    }
   ],
   "source": [
    "def print_sorted_dict_by_val_desc(input_dict):\n",
    "    converted_list = []\n",
    "    for k,v in input_dict.items():\n",
    "        a, b = v, k\n",
    "        converted_list.append([a,b])\n",
    "    \n",
    "    for elem in sorted(converted_list, reverse=True):\n",
    "        print('{}: {}'.format(elem[1],elem[0]))\n",
    "    \n",
    "print(\"Number of posts by hour [High->Low]: \") \n",
    "print_sorted_dict_by_val_desc(counts_by_hour)\n",
    "    \n",
    "print(\"\\n\")\n",
    "    \n",
    "print(\"Number of comments by hour [High->Low]: \")    \n",
    "print_sorted_dict_by_val_desc(comments_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the distribution of `\"Ask HN\"` posts and comments by hour (printed above), We can see a pattern. In the morning and late at night, we do not see much activity from the users. However, in the afternoon leading up to the evening/ late-evening, we see more activity from the users.\n",
    "\n",
    "Let's now calculate the average number of comments per post for posts created during each hour of the day. We can create a list of lists named `avg_by_hour` where each inner lists will have 2 elements - the first element being the hour and the second one is average comments per post in that hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['09', 5.58],\n",
       " ['13', 14.74],\n",
       " ['10', 13.44],\n",
       " ['14', 13.23],\n",
       " ['16', 16.8],\n",
       " ['23', 7.99],\n",
       " ['12', 9.41],\n",
       " ['17', 11.46],\n",
       " ['15', 38.59],\n",
       " ['21', 16.01],\n",
       " ['20', 21.52],\n",
       " ['02', 23.81],\n",
       " ['18', 13.2],\n",
       " ['03', 7.8],\n",
       " ['05', 10.09],\n",
       " ['19', 10.8],\n",
       " ['01', 11.38],\n",
       " ['22', 6.75],\n",
       " ['08', 10.25],\n",
       " ['04', 7.17],\n",
       " ['00', 8.13],\n",
       " ['06', 9.02],\n",
       " ['07', 7.85],\n",
       " ['11', 11.05]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "\n",
    "for hour in comments_by_hour:\n",
    "    avg_cmnts_per_post = round(comments_by_hour[hour]/counts_by_hour[hour],2)\n",
    "    avg_by_hour.append([hour, avg_cmnts_per_post])\n",
    "    \n",
    "avg_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we now have the results we need, this format makes it hard to identify the hours with the highest values. Let's finish by sorting the list of lists and printing the five highest values in a format that's easier to read.\n",
    "\n",
    "Below, we create a list `swap_avg_by_hour` that equals `avg_by_hour` wit\n",
    "h swapped columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5.58, '09'],\n",
       " [14.74, '13'],\n",
       " [13.44, '10'],\n",
       " [13.23, '14'],\n",
       " [16.8, '16'],\n",
       " [7.99, '23'],\n",
       " [9.41, '12'],\n",
       " [11.46, '17'],\n",
       " [38.59, '15'],\n",
       " [16.01, '21'],\n",
       " [21.52, '20'],\n",
       " [23.81, '02'],\n",
       " [13.2, '18'],\n",
       " [7.8, '03'],\n",
       " [10.09, '05'],\n",
       " [10.8, '19'],\n",
       " [11.38, '01'],\n",
       " [6.75, '22'],\n",
       " [10.25, '08'],\n",
       " [7.17, '04'],\n",
       " [8.13, '00'],\n",
       " [9.02, '06'],\n",
       " [7.85, '07'],\n",
       " [11.05, '11']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "\n",
    "for elem in avg_by_hour:\n",
    "    temp_list = [elem[1], elem[0]]\n",
    "    swap_avg_by_hour.append(temp_list)\n",
    "    \n",
    "swap_avg_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the `sorted()` [function](https://docs.python.org/3/library/functions.html#sorted) to sort `swap_avg_by_hour` in descending order. Since the first column of this list is the average number of comments, sorting the list will sort by the average number of comments. We can save the sorted result in `sorted_swap`.\n",
    "\n",
    "Finally, we can print the top 5 hours for `\"Ask HN\"` posts' comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments: \n",
      "\n",
      "\n",
      "15:00: 38.59 average comments per post\n",
      "02:00: 23.81 average comments per post\n",
      "20:00: 21.52 average comments per post\n",
      "16:00: 16.80 average comments per post\n",
      "21:00: 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "sorted_swap = sorted(swap_avg_by_hour, reverse=True)\n",
    "\n",
    "print(\"Top 5 Hours for Ask Posts Comments: \")\n",
    "print(\"\\n\")\n",
    "for elem in sorted_swap[:5]:\n",
    "    print('{}: {:.2f} average comments per post'.format(dt.datetime.strptime(elem[1], \"%H\").strftime(\"%H:%M\"), elem[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above data, it can be concluded that to have a higher chance of receiving comments, a post should be created in the following hours (*Eastern Time US* [as per the documentation](https://www.kaggle.com/hacker-news/hacker-news-posts)):\n",
    "- 15:00\n",
    "- 02:00\n",
    "- 20:00\n",
    "- 16:00\n",
    "- 21:00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's determine if ask posts or show posts receive more points on average. We can use the `avg_no_of()` function that was used earlier to calculate average comments. For the second parameter of this function, now, we will provide `3` as it is the index of the `num_points` column in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average points for posts asking ('Ask HN'): 15.06\n",
      "Average points for posts showing ('Show HN'): 27.56\n"
     ]
    }
   ],
   "source": [
    "avg_ask_points = avg_no_of(ask_posts, 3)\n",
    "avg_show_points = avg_no_of(show_posts, 3)\n",
    "\n",
    "print(\"Average points for posts asking ('Ask HN'): \" + str(round(avg_ask_points, 2)))\n",
    "print(\"Average points for posts showing ('Show HN'): \" + str(round(avg_show_points,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking from the above data, it is clear that `\"Ask HN\"` posts receive less points on average (**15.06**) than `\"Show HN\"` posts (**27.56**). In terms of average comments, it was the opposite.\n",
    "\n",
    "Since show posts are more likely to receive more points, we'll focus our remaining analysis just on these posts. Next, we'll determine if show posts created at a certain time are more likely to attract points. First let's find out the total points for each available hours below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points by hour [High->Low]: \n",
      "16: 2634\n",
      "12: 2543\n",
      "17: 2521\n",
      "13: 2438\n",
      "15: 2228\n",
      "18: 2215\n",
      "14: 2187\n",
      "22: 1856\n",
      "20: 1819\n",
      "19: 1702\n",
      "23: 1526\n",
      "11: 1480\n",
      "00: 1173\n",
      "21: 866\n",
      "01: 700\n",
      "10: 681\n",
      "03: 679\n",
      "09: 553\n",
      "08: 519\n",
      "07: 494\n",
      "04: 386\n",
      "06: 375\n",
      "02: 340\n",
      "05: 104\n"
     ]
    }
   ],
   "source": [
    "result_list = []\n",
    "\n",
    "for each_row in show_posts:\n",
    "    temp_list = [each_row[6], int(each_row[3])]\n",
    "    result_list.append(temp_list)\n",
    "    \n",
    "points_by_hour = {}\n",
    "\n",
    "for elem in result_list:\n",
    "    dt_obj = dt.datetime.strptime(elem[0], \"%m/%d/%Y %H:%M\")\n",
    "    hour = dt_obj.strftime(\"%H\")\n",
    "    if hour not in points_by_hour:\n",
    "        points_by_hour[hour] = elem[1]\n",
    "    else:\n",
    "        points_by_hour[hour] += elem[1]\n",
    "        \n",
    "print(\"Number of points by hour [High->Low]: \")    \n",
    "print_sorted_dict_by_val_desc(points_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now calculate the average number of points per post for posts created during each hour of the day. We can create a list of lists named `avg_pts_by_hour` where each inner lists will have 2 elements - the first element being the hour and the second one is average points per post in that hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['14', 20.44],\n",
       " ['22', 26.14],\n",
       " ['18', 20.32],\n",
       " ['07', 14.53],\n",
       " ['20', 22.74],\n",
       " ['05', 2.26],\n",
       " ['16', 24.39],\n",
       " ['19', 15.47],\n",
       " ['15', 19.21],\n",
       " ['03', 12.57],\n",
       " ['17', 25.21],\n",
       " ['06', 8.52],\n",
       " ['02', 5.86],\n",
       " ['13', 28.68],\n",
       " ['08', 10.81],\n",
       " ['21', 7.94],\n",
       " ['04', 8.21],\n",
       " ['11', 25.52],\n",
       " ['12', 34.84],\n",
       " ['23', 22.44],\n",
       " ['09', 12.29],\n",
       " ['01', 11.67],\n",
       " ['10', 11.54],\n",
       " ['00', 21.33]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_pts_by_hour = []\n",
    "\n",
    "for hour in points_by_hour:\n",
    "    avg_pts_per_post = round(points_by_hour[hour]/counts_by_hour[hour],2)\n",
    "    avg_pts_by_hour.append([hour, avg_pts_per_post])\n",
    "    \n",
    "avg_pts_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we now have the results we need, this format makes it hard to identify the hours with the highest values. Let's finish by sorting the list of lists and printing the five highest values in a format that's easier to read.\n",
    "\n",
    "Below, we create a list `swap_avg_pts_by_hour` that equals `avg_pts_by_hour` with swapped columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[20.44, '14'],\n",
       " [26.14, '22'],\n",
       " [20.32, '18'],\n",
       " [14.53, '07'],\n",
       " [22.74, '20'],\n",
       " [2.26, '05'],\n",
       " [24.39, '16'],\n",
       " [15.47, '19'],\n",
       " [19.21, '15'],\n",
       " [12.57, '03'],\n",
       " [25.21, '17'],\n",
       " [8.52, '06'],\n",
       " [5.86, '02'],\n",
       " [28.68, '13'],\n",
       " [10.81, '08'],\n",
       " [7.94, '21'],\n",
       " [8.21, '04'],\n",
       " [25.52, '11'],\n",
       " [34.84, '12'],\n",
       " [22.44, '23'],\n",
       " [12.29, '09'],\n",
       " [11.67, '01'],\n",
       " [11.54, '10'],\n",
       " [21.33, '00']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swap_avg_pts_by_hour = []\n",
    "\n",
    "for elem in avg_pts_by_hour:\n",
    "    temp_list = [elem[1], elem[0]]\n",
    "    swap_avg_pts_by_hour.append(temp_list)\n",
    "    \n",
    "swap_avg_pts_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the `sorted()` [function](https://docs.python.org/3/library/functions.html#sorted) to sort `swap_avg_pts_by_hour` in descending order. Since the first column of this list is the average number of points, sorting the list will sort by the average number of points. We can save the sorted result in `sorted_swap_points`.\n",
    "\n",
    "Finally, we can print the top 5 hours for `\"Show HN\"` posts' points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Show Posts Points: \n",
      "\n",
      "\n",
      "12:00: 34.84 average points per post\n",
      "13:00: 28.68 average points per post\n",
      "22:00: 26.14 average points per post\n",
      "11:00: 25.52 average points per post\n",
      "17:00: 25.21 average points per post\n"
     ]
    }
   ],
   "source": [
    "sorted_swap_points = sorted(swap_avg_pts_by_hour, reverse=True)\n",
    "\n",
    "print(\"Top 5 Hours for Show Posts Points: \")\n",
    "print(\"\\n\")\n",
    "for elem in sorted_swap_points[:5]:\n",
    "    print('{}: {:.2f} average points per post'.format(dt.datetime.strptime(elem[1], \"%H\").strftime(\"%H:%M\"), elem[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above data, it can be concluded that to have a higher chance of receiving comments, a post should be created in the following hours (*Eastern Time US* [as per the documentation](https://www.kaggle.com/hacker-news/hacker-news-posts)):\n",
    "\n",
    "- 12:00\n",
    "- 13:00\n",
    "- 22:00\n",
    "- 11:00\n",
    "- 17:00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this project, we analyzed ask posts and show posts to determine which type of post and time receive the most comments on average and most points on average. \n",
    "\n",
    "Based on our analysis, to maximize the amount of comments a post receives, we'd recommend the post be categorized as ask post and created between 15:00 and 16:00 (3:00 pm est - 4:00 pm est).\n",
    "\n",
    "On the other hand, while analyzing which type of posts get more points, we found out that it's show posts that get more points. Based on our analysis, to maximize the amount of points a post receives, we'd recommend the post be categorized as show post and created between 12:00 and 13:00 (12:00 pm est - 1:00 pm est).\n",
    "\n",
    "However, it should be noted that the data set we analyzed excluded posts without any comments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
