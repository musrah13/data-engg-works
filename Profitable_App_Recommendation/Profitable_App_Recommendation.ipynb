{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Profitable App Profile Recommendation\n",
    "\n",
    "In this project we analyze the data available from the various apps available on Google Play and the App Store that our company develops to find out user engagement. As all of our apps are free, the revenue is generated trhough in-app ads. The more the user interacts with theem, the more profitable the apps become.\n",
    "\n",
    "The main goal of the project is to find out those apps that are potentially generating most revenue. In other words, the goal is to help the developers understand what type of apps are likely to attract more users on Google Play and the App Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opening and Exploring the datasets\n",
    "\n",
    "As of September 2018, there were approximately 2 million iOS apps available on the App Store, and 2.1 million Android apps on Google Play.\n",
    "\n",
    "Collecting data for over 4 million apps requires a significant amount of time and money, so we'll try to analyze a sample of the data instead. To avoid spending resources on collecting new data ourselves, we should first try to see if we can find any relevant existing data at no cost. Luckily, these are two data sets that seem suitable for our goals:\n",
    "\n",
    "A [data set](https://www.kaggle.com/lava18/google-play-store-apps) containing data about approximately 10,000 Android apps from Google Play; the data was collected in August 2018. You can download the data set directly from this [link](https://dq-content.s3.amazonaws.com/350/googleplaystore.csv).\n",
    "\n",
    "A [data set](https://www.kaggle.com/ramamet4/app-store-apple-data-set-10k-apps) containing data about approximately 7,000 iOS apps from the App Store; the data was collected in July 2017. You can download the data set directly from this [link](https://dq-content.s3.amazonaws.com/350/AppleStore.csv).\n",
    "\n",
    "As we have the data available to us, we can start by opening the dataset and then explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "opened_file_google = open('dataset\\googleplaystore.csv', encoding=\"utf8\")\n",
    "read_file_google = reader(opened_file_google)\n",
    "apps_data_google = list(read_file_google)\n",
    "google_header = apps_data_google[0]\n",
    "google_data = apps_data_google[1:]\n",
    "\n",
    "opened_file_apple = open('dataset\\AppleStore.csv', encoding=\"utf8\")\n",
    "read_file_apple = reader(opened_file_apple)\n",
    "apps_data_apple = list(read_file_apple)\n",
    "apple_header = apps_data_apple[0]\n",
    "apple_data = apps_data_apple[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the dataset easily explorable, a function `explore_data()` is created below. It takes as input the dataset to be explored along with the start row and end row for the exploration. It can also provide us with the information such as the total number of rows and columns the dataset has. This function can be used to explore the data repeatedly with great readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_data(dataset, start, end, rows_and_columns=False):\n",
    "    dataset_slice = dataset[start:end]    \n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print('\\n') # adds a new (empty) line after each row\n",
    "\n",
    "    if rows_and_columns:\n",
    "        print('Number of rows:', len(dataset))\n",
    "        print('Number of columns:', len(dataset[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to use the `explore_data()` function to start exploring the data. Below we printed out first 5 rows for each dataset. First, the Google store data and then the Apple play store data. \n",
    "\n",
    "As can be seen from below, Google play store dataset has total **10842** rows including the header row (that has all the column names) and **13** columns in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['Coloring book moana', 'ART_AND_DESIGN', '3.9', '967', '14M', '500,000+', 'Free', '0', 'Everyone', 'Art & Design;Pretend Play', 'January 15, 2018', '2.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['U Launcher Lite ‚Äì FREE Live Cool Themes, Hide Apps', 'ART_AND_DESIGN', '4.7', '87510', '8.7M', '5,000,000+', 'Free', '0', 'Everyone', 'Art & Design', 'August 1, 2018', '1.2.4', '4.0.3 and up']\n",
      "\n",
      "\n",
      "Number of rows: 10841\n",
      "Number of columns: 13\n"
     ]
    }
   ],
   "source": [
    "explore_data(google_data, 0, 3, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, Apple store dataset has **7198** rows including the header row and a grand total of **16** columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['284882215', 'Facebook', '389879808', 'USD', '0.0', '2974676', '212', '3.5', '3.5', '95.0', '4+', 'Social Networking', '37', '1', '29', '1']\n",
      "\n",
      "\n",
      "['389801252', 'Instagram', '113954816', 'USD', '0.0', '2161558', '1289', '4.5', '4.0', '10.23', '12+', 'Photo & Video', '37', '0', '29', '1']\n",
      "\n",
      "\n",
      "['529479190', 'Clash of Clans', '116476928', 'USD', '0.0', '2130805', '579', '4.5', '4.5', '9.24.12', '9+', 'Games', '38', '5', '18', '1']\n",
      "\n",
      "\n",
      "Number of rows: 7197\n",
      "Number of columns: 16\n"
     ]
    }
   ],
   "source": [
    "explore_data(apple_data, 0, 3, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now take a look at the column names (header row) for each dataset separately. \n",
    "\n",
    "Firstly, we look at the column names of the Google play store dataset. A detailed description of the columns are given in the [documentation](https://www.kaggle.com/lava18/google-play-store-apps).\n",
    "\n",
    "Some of the useful columns for our analysis can be `'App', 'Category', 'Rating', 'Reviews', 'Size', 'Installs', 'Type', 'Content Rating', 'Genres'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['App', 'Category', 'Rating', 'Reviews', 'Size', 'Installs', 'Type', 'Price', 'Content Rating', 'Genres', 'Last Updated', 'Current Ver', 'Android Ver']\n"
     ]
    }
   ],
   "source": [
    "print(google_header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us take a glance at the column names of the Apple store dataset. A detailed description of the columns are given in the [documentation](https://www.kaggle.com/ramamet4/app-store-apple-data-set-10k-apps). \n",
    "\n",
    "From these set of columns, it looks like `'track_name', 'currency', 'price', 'rating_count_tot', 'rating_count_ver', 'prime_genre'` are some of the columns that can be useful for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'track_name', 'size_bytes', 'currency', 'price', 'rating_count_tot', 'rating_count_ver', 'user_rating', 'user_rating_ver', 'ver', 'cont_rating', 'prime_genre', 'sup_devices.num', 'ipadSc_urls.num', 'lang.num', 'vpp_lic']\n"
     ]
    }
   ],
   "source": [
    "print(apple_header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deleting wrong data\n",
    "\n",
    "The Google Play data set has a dedicated [discussion section](https://www.kaggle.com/lava18/google-play-store-apps/discussion), and we can see that [one of the discussions](https://www.kaggle.com/lava18/google-play-store-apps/discussion/66015) describes an error for a certain row.\n",
    "\n",
    "The row in question is `google_data[10472]`. According to the discussion this entry has missing `'Rating'` and a column shift happened for next columns. Let's first print out this row in conjunction with the header row and another valid row so that we can better identify the wrongness of the entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['App', 'Category', 'Rating', 'Reviews', 'Size', 'Installs', 'Type', 'Price', 'Content Rating', 'Genres', 'Last Updated', 'Current Ver', 'Android Ver'] \n",
      "\n",
      " ['Life Made WI-Fi Touchscreen Photo Frame', '1.9', '19', '3.0M', '1,000+', 'Free', '0', 'Everyone', '', 'February 11, 2018', '1.0.19', '4.0 and up'] \n",
      "\n",
      " ['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n"
     ]
    }
   ],
   "source": [
    "print(google_header, '\\n\\n', google_data[10472], '\\n\\n', google_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After further analyzing the **10472** entry, it looks like the data for the `'Category'` column is missing and for that reason all the data in the row shifted one column to the left. Clearly this entry is wrong and we will delete this entry below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting wrong entry for 10472\n",
    "\n",
    "del google_data[10472]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print and verify whether that entry was truly deleted from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['osmino Wi-Fi: free WiFi', 'TOOLS', '4.2', '134203', '4.1M', '10,000,000+', 'Free', '0', 'Everyone', 'Tools', 'August 7, 2018', '6.06.14', '4.4 and up']\n"
     ]
    }
   ],
   "source": [
    "print(google_data[10472])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Duplicate Data\n",
    "\n",
    "Now, we are going to look for duplicate data/ entries (multiple entry for the same app) in both the datasets. If we find duplicate data/entries, we are going to remove all of them keeping only the most recent entry. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Play Store\n",
    "\n",
    "**First, we take a look at the *Google play store* dataset.** We can decide on which entry is the most recent depending on the count of the user reviews which can be found on the column: `'Reviews'`. Amongst all the duplicate entries, the entry that has the maximum number of user reviews, we can determine that as the most recent entry for that app and use that for our analysis.\n",
    "\n",
    "We can write a function `detect_uniques_and_duplicates()` that will detect duplicate entries for an app for a given dataset and store the duplicate apps' names as a list named `duplicate_entries`. It will also store the unique apps' names as another list named `unique_entries`. This function will also take a column index of the dataset based on which the duplicity will be checked in the dataset.\n",
    "\n",
    "Finally, we will get both lists (`duplicate_entries`, `unique_entries`) as output from the function `detect_uniques_and_duplicates()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_uniques_and_duplicates(dataSet, col):\n",
    "    unique_entries = []\n",
    "    duplicate_entries = []\n",
    "    \n",
    "    for each_row in dataSet:\n",
    "        if each_row[col] in unique_entries:\n",
    "            duplicate_entries.append(each_row[col])\n",
    "        else:\n",
    "            unique_entries.append(each_row[col])\n",
    "    \n",
    "    return duplicate_entries, unique_entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we use `detect_uniques_and_duplicates()` function on Google Play store dataset and find out that there are **1181** duplicate data in it. Note, that, as a second parameter/ input to the function, `0` is used. Because, the column `'App'` which is the first column (index `0`) for each row in the dataset is the column that's used to check for duplicity. \n",
    "\n",
    "Some of the duplicate apps' names in the Google Play store dataset are also shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of duplicate entries in the Google play store dataset: 1181\n",
      "\n",
      "\n",
      "Some of the apps that has duplicate entries in the Google play store dataset: \n",
      "\n",
      "\n",
      "['Quick PDF Scanner + OCR FREE', 'Box', 'Google My Business', 'ZOOM Cloud Meetings', 'join.me - Simple Meetings', 'Box', 'Zenefits', 'Google Ads', 'Google My Business', 'Slack', 'FreshBooks Classic', 'Insightly CRM', 'QuickBooks Accounting: Invoicing & Expenses']\n"
     ]
    }
   ],
   "source": [
    "dupDataGoogle, uniqueDataGoogle = detect_uniques_and_duplicates(google_data, 0)\n",
    "print(\"Total number of duplicate entries in the Google play store dataset: \" + str(len(dupDataGoogle)))\n",
    "print(\"\\n\")\n",
    "print(\"Some of the apps that has duplicate entries in the Google play store dataset: \")\n",
    "print(\"\\n\")\n",
    "print(dupDataGoogle[:13])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have found **1181** duplicate entries, we can find out what the total number of unique entries should be by removing it from the total data count. As can be seen below, the total number of unique entries should be **9659**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected unique entries:  9659\n"
     ]
    }
   ],
   "source": [
    "expected_length = len(google_data)-len(dupDataGoogle)\n",
    "print(\"Expected unique entries: \", expected_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To remove the duplicates, we will create a dictionary `reviews_max`, where each dictionary key is a unique app name and the corresponding dictionary value is the highest number of reviews of that app. Therefore, the length of this dictionary should **9659** as this is the number of expected unique entries. We can verify that by printing the length of `reviews_max`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Length:  9659\n",
      "Actual Length:  9659\n"
     ]
    }
   ],
   "source": [
    "reviews_max = {}\n",
    "\n",
    "for each_row in google_data:\n",
    "    name = each_row[0]\n",
    "    n_reviews = float(each_row[3]) # 3 is the column index for 'Reviews' column in the dataset\n",
    "    if name in reviews_max and reviews_max[name] < n_reviews:\n",
    "        reviews_max[name] = n_reviews\n",
    "    if name not in reviews_max:\n",
    "        reviews_max[name] = n_reviews\n",
    "\n",
    "print(\"Expected Length: \", expected_length)\n",
    "print(\"Actual Length: \", len(reviews_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use the information stored in the dictionary `reviews_max` and create a new data set `android_clean`, which will have only one entry per app (and for each app, we'll only select the entry with the highest number of reviews). In the code cell below:\n",
    "\n",
    "- We start by initializing two empty lists, `android_clean` and `already_added`.\n",
    "- We loop through the `google_data` data set, and for every iteration:\n",
    "    - We isolate the name of the app and the number of reviews.\n",
    "    - We add the current row (`each_row`) to the `android_clean` list, and the app name (`name`) to the `already_added` list if:\n",
    "        - The number of reviews of the current app matches the number of reviews of that app as described in the `reviews_max` dictionary; and\n",
    "        - The name of the app is not already in the `already_added` list. We need to add this supplementary condition to account for those cases where the highest number of reviews of a duplicate app is the same for more than one entry (for example, the Box app has three entries, and the number of reviews is the same). If we just check for `reviews_max[name] == n_reviews`, we'll still end up with duplicate entries for some apps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "android_clean = []\n",
    "already_added = []\n",
    "\n",
    "for each_row in google_data:\n",
    "    name = each_row[0]\n",
    "    n_reviews = float(each_row[3])\n",
    "    if n_reviews == reviews_max[name] and name not in already_added:\n",
    "        android_clean.append(each_row)\n",
    "        already_added.append(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can verify the length (number of rows) of `android_clean` as it should be the same as the length of `reviews_max` which is **9659** by exploring the dataset using `explore_data()` function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_data(android_clean, 0, 5, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appl Store\n",
    "\n",
    "We can now check for duplicate entries in the Apple store dataset using the `detect_uniques_and_duplicates()` function where `track_name` column (index `1` for each row) of the dataset is considered to be used to check for duplicity. \n",
    "\n",
    "Below we get 2 apps that have apparently duplicate entries. However, from the [discussion here](https://www.kaggle.com/ramamet4/app-store-apple-data-set-10k-apps/discussion/90409), it is evident that these are not duplicates; rather, they different apps with same name. Therefore, we do not have to remove any entry in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupDataApple, uniqueDataApple = detect_uniques_and_duplicates(apple_data, 1)\n",
    "print(\"Apps with similar names but eventually not duplicates: \", \"\\n\\n\")\n",
    "print(dupDataApple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Non-English Apps\n",
    "\n",
    "### Part One\n",
    "\n",
    "Note, we use English for the apps we develop at our company, and we'd like to analyze only the apps that are directed toward an English-speaking audience. However, if we explore the data long enough, we'll find that both data sets have apps with names that suggest they are not directed toward an English-speaking audience. We're not interested in keeping these apps, so we'll remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(android_clean[4412][0])\n",
    "print(android_clean[7940][0])\n",
    "print(\"\\n\")\n",
    "print(apple_data[813][1])\n",
    "print(apple_data[6731][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start by writing a function `detect_EnglisName()` that takes in a string and return `False` if there's any character in the string that doesn't beelong to the set of English characters, otherwise it returns true.\n",
    "\n",
    "We will take the help of ASCII codes in order to solve this. Each character in a string has an ASCII code associated with it. No English language character has an ASCII code more than 127 starting from 0. Therefore, we can determine a non-English character if its ASCII code is more than 127 and less than 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_EnglisName(appName):\n",
    "    for each_char in appName:\n",
    "        if ord(each_char) > 127 or ord(each_char) < 0:\n",
    "            return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We verify our function `detect_EnglisName()` below with some strings and it works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(detect_EnglisName('Instagram'))\n",
    "print(detect_EnglisName('Áà±Â•áËâ∫PPS -„ÄäÊ¨¢‰πêÈ¢Ç2„ÄãÁîµËßÜÂâßÁÉ≠Êí≠'))\n",
    "print(detect_EnglisName('Docs To Go‚Ñ¢ Free Office Suite'))\n",
    "print(detect_EnglisName('Instachat üòú'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like, the function couldn't correctly identify certain English app names like `'Docs To Go‚Ñ¢ Free Office Suite'` and `'Instachat üòú'`. This is because emojis and characters like `‚Ñ¢` fall outside the ASCII range and have corresponding numbers over 127."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('‚Ñ¢ :', ord('‚Ñ¢'))\n",
    "print('üòú :', ord('üòú'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part Two\n",
    "\n",
    "If we're going to use the function we've created, we'll lose useful data since many English apps will be incorrectly labeled as non-English. To minimize the impact of data loss, we'll only remove an app if its name has more than three characters with corresponding numbers falling outside the ASCII range. This means all English apps with up to three emoji or other special characters will still be labeled as English.\n",
    "\n",
    "It is not a perfect solution, but surely better than the previous. Let's edit the function `detect_EnglisName()` to fit the idea and we'll later use it to filter out the non-English apps from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_EnglisName(appName):\n",
    "    count = 0\n",
    "    for each_char in appName:\n",
    "        if ord(each_char) > 127:\n",
    "            count += 1\n",
    "            if count > 3:\n",
    "                return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the modified function to check whether it is working properly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(detect_EnglisName('Instagram'))\n",
    "print(detect_EnglisName('Áà±Â•áËâ∫PPS -„ÄäÊ¨¢‰πêÈ¢Ç2„ÄãÁîµËßÜÂâßÁÉ≠Êí≠'))\n",
    "print(detect_EnglisName('Docs To Go‚Ñ¢ Free Office Suite'))\n",
    "print(detect_EnglisName('Instachat üòú'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now confirm, it is working properly and is ready to be used for filtering out non-English apps from both datasets.\n",
    "\n",
    "So, below we create a function `removeNonEnglishApps()` that takes in the dataset and the index of the column which has the name of an app. It loops through the provided data set. If an app name is identified as English, the whole row for that app is appended to a separate list `english_apps`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeNonEnglishApps(dataSet, col):\n",
    "    english_apps = []\n",
    "    for each_row in dataSet:\n",
    "        if detect_EnglisName(each_row[col]):\n",
    "            english_apps.append(each_row)\n",
    "    \n",
    "    return english_apps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part Three\n",
    "\n",
    "Below we apply the function `removeNonEnglishApps()` on both the Google Play Store and Apple Sotre dataset to filter out any non-English apps.\n",
    "\n",
    "Two clean datasets with only non-English apps are now stored in `android_clean_English` for Google Play Store and `ios_clean_English` for Apple Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "android_clean_English = removeNonEnglishApps(android_clean, 0)\n",
    "ios_clean_English = removeNonEnglishApps(apple_data, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After exploring `android_clean_English`, we can see the number of rows have decreased. Further we can find out exactly how many non-English apps we removed. The total number of non-English apps in the Google Play Store dataset was **62**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_data(android_clean_English, 0, 3, True)\n",
    "print(\"\\n\")\n",
    "print(\"Total Non-English apps removed: \", len(android_clean)-len(android_clean_English))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After exploring `ios_clean_English`, we can see the number of rows have also decreased here. Further we can find out exactly how many non-English apps we removed. The total number of non-English apps in the Apple Play Store dataset was **1042**, significantly more than Google Play Store dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_data(ios_clean_English, 0, 3, True)\n",
    "print(\"\\n\")\n",
    "print(\"Total Non-English apps removed: \", len(apple_data)-len(ios_clean_English))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing non-Free apps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we mentioned earlier, we only build apps that are free to download and install, and our main source of revenue consists of in-app ads. Our data sets contain both free and non-free apps; we'll need to isolate only the free apps for our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Play Store\n",
    "\n",
    "We first isolate the free apps from the so far cleaned Google Play Store dataset: `android_clean_English`. The `'Price'` column of the dataset contains information about the app - whether it is free or not. If it is `0`, then it is free. Otherwise, it is not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(google_header)\n",
    "print(\"\\n\")\n",
    "print(android_clean_English[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this column index (`7` for each row) in the dataset to extract out the free apps in a new set of data: `android_free_clean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "android_free_clean = []\n",
    "for each_row in android_clean_English:\n",
    "    if each_row[7] == \"0\":\n",
    "        android_free_clean.append(each_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the extraction, we can start exploring `android_free_clean`. We find that the length of the dataset has shrunk even more. So, finally, the number of free apps is **8864**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_data(android_free_clean, 0, 3, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apple Store\n",
    "\n",
    "We first isolate the free apps from the so far cleaned Apple Store dataset: `ios_clean_English`. The `'price'` column of the dataset contains information about the app - whether it is free or not. Unlike Google Play store data, this column has numerical value as the price. If it is more than `0`, then it is not a free app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(apple_header)\n",
    "print(\"\\n\")\n",
    "print(ios_clean_English[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this column index (`4` for each row) in the dataset to extract out the free apps in a new set of data: `ios_free_clean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ios_free_clean = []\n",
    "for each_row in ios_clean_English:\n",
    "    if float(each_row[4]) <= 0:\n",
    "        ios_free_clean.append(each_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the extraction, we can start exploring `ios_free_clean`. We find that the length of the dataset has shrunk even more. So, finally, the number of free apps is **3222**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "explore_data(ios_free_clean, 0, 3, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding App Profile\n",
    "\n",
    "### Part One\n",
    "\n",
    "As we mentioned earlier, our aim is to determine the kinds of apps that are likely to attract more users because our revenue is highly influenced by the number of people using our apps.\n",
    "\n",
    "To minimize risks and overhead, our validation strategy for an app idea is comprised of three steps:\n",
    "\n",
    "1. Build a minimal Android version of the app, and add it to Google Play.\n",
    "2. If the app has a good response from users, we develop it further.\n",
    "3. If the app is profitable after six months, we build an iOS version of the app and add it to the App Store.\n",
    "\n",
    "Because our end goal is to add the app on both Google Play and the App Store, we need to find app profiles that are successful on both markets.\n",
    "\n",
    "We can start analysis by getting an idea about the most common app genres for both android and ios market. For this, we'll need to build frequency tables for a few columns in our data sets.\n",
    "\n",
    "Let's again take a look at both data sets' columns below and decide which column we should take into account while building the frequency table for each dataset.\n",
    "\n",
    "We will use `'Genres'` and `'Category'` columns for generating the Google Play Store frequency table. On the other hand, `'prime_genre'` will be used to generate the Appl Store frequency table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Google Play Store dataset column names: \")\n",
    "print(google_header)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Apple Store dataset column names: \")\n",
    "print(apple_header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part Two\n",
    "\n",
    "We'll build two functions we can use to analyze the frequency tables:\n",
    "- One function named `freq_table()` to generate frequency tables that show percentages\n",
    "- Another function named `display_table()` we can use to display the percentages in a descending order\n",
    "\n",
    "First, we will start implementing the function `freq_table()` below.\n",
    "- It takes in two inputs: `dataset` (which is expected to be a list of lists) and `index` (which is expected to be an integer).\n",
    "- The function will return the frequency table (as a dictionary) for any column we want. The frequencies should also be expressed as percentages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_table(dataset, index):\n",
    "    percent_dict = {}\n",
    "    for each_row in dataset:\n",
    "        key = each_row[index]\n",
    "        if key in percent_dict:\n",
    "            percent_dict[key] += 1\n",
    "        else:\n",
    "            percent_dict[key] = 1\n",
    "    \n",
    "    for i in percent_dict:\n",
    "        percent_dict[i] = round((percent_dict[i]/len(dataset)) * 100, 2)\n",
    "    \n",
    "    return percent_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, below, the `display_table()` function is implemented. It:\n",
    "- Takes in two parameters: `dataset` and `index`. `dataset` is expected to be a list of lists, and `index` is expected to be an integer.\n",
    "- Generates a frequency table using the `freq_table()` function\n",
    "- Transforms the frequency table into a list of tuples `table_display`, then sorts the list in a descending order using `sorted()` built-in function. The `sorted()` function does not work on dictionaries properly. However, it works on lists. For that reason, we have converted the dictionary we created from the `freq_table()` function into a list o tuples where for each tuple, the dictionary value comes first and the key comes second. As we are going to sort the list in a descending order, the second parameter `reverse` is set to `True` for the `sorted()` function.\n",
    "- Finally, prints the entries of the frequency table in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_table(dataset, index):\n",
    "    table = freq_table(dataset, index)\n",
    "    table_display = []\n",
    "    for key in table:\n",
    "        key_val_as_tuple = (table[key], key)\n",
    "        table_display.append(key_val_as_tuple)\n",
    "\n",
    "    table_sorted = sorted(table_display, reverse = True)\n",
    "    for entry in table_sorted:\n",
    "        print(entry[1] + ': ' + str(entry[0]) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part Three\n",
    "\n",
    "First, we invoke the `display_table()` function for the `ios_free_clean` dataset and the `prime_genre` column (which is the index `11` for each row in the dataset) is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_table(ios_free_clean, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the data above, **Games** genre have the most apps available with 58.16% of the total. This is so much more in number than the second in the list: **Entertainment** (7.88%). After that most of the genres have number of apps evenly distrubted amongst them. Looks like Apple Store is mostly focused on offering apps that are fun and less on practical apps.\n",
    "\n",
    "However, we are only analyzing free English apps and this might not be the real picture throughout the whole of Apple Store. For that, it will be unwise to recommend which apps are most used by the user in this platform. But we can put this information to use later to find usage data.\n",
    "\n",
    "Now let us take a look at the Google Play Store platform's data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we invoke the `display_table()` function for the `android_free_clean` dataset and the `'Category'` column (which is the index `1` for each row in the dataset) is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_table(android_free_clean, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the data above, analyzing the `'Category'` column for the Google Play Store dataset, where we have only considered free English apps, **FAMILY** apps are the most in numbers (around 19%) of the total. The second most apps in number are the **GAME** apps with around 10% (almost half of **FAMILY**) of the total. Third in line are the **TOOLS** apps with 8.46% of the total. After that, most category apps are evenly distributed.\n",
    "\n",
    "It does look like there is somewhat a blance in number of apps offered in different categories in this platform. However, upon further inspection, going through the [Google Play Store website](https://play.google.com/store/apps), the [**FAMILY**](https://play.google.com/store/apps/category/FAMILY) apps are mostly for kids. Apart from that, most [**GAME**](https://play.google.com/store/apps/category/GAME) apps are also geenerally for kids. From this viewpoint, it potentially looks like that Google Play Store offers most of its apps for kids. However, it's not possible to say confidently that this is the case for most usage of apps because availability does not readily translate to demand.\n",
    "\n",
    "We can further analyze the `'Genres'` column in this dataset to see how the distribution of different types of apps are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we invoke the `display_table()` function for the `android_free_clean` dataset again but this time the `'Genres'` column (which is the index `9` for each row in the dataset) is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_table(android_free_clean, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at this data, it tells a very different story for Google Play Store's app distribution than when we used `'Category'` column for our analysis. It looks like under `'Genres'` column the app \"categories\" are more granular. Therefore, going forward with our analysis for Google Play Store we will be using `'Geenres'` column only in the future. \n",
    "\n",
    "Here, we see that **Tools** genre has the most numbers of apps (8.45%) followed by a close second: **Entertainment** with 6.07%. After that **Education**, **Business**, **Productivity**, **Lifestyle**, **Finance**, **Medical**, **Sports**, **Personalization**, **Communication**, **Action**, and **Health & Fitness** all are above 3% and close to each other in terms of percentage of total numbers.\n",
    "\n",
    "It tells us that in Google Play Store, unlike Apple Store, there is a balance in apps offered. However, again, as we are basing our opinion mainly from filtered data (free English apps), it might not hold true for the whole of both platforms. Apart from that, based on this data, if it were to be recommended which kind of app is more used, it will be unwise. Because, we can only see from this data how much of different categories/ genres of apps are offered/ available in the platforms, but cannot have a concrete idea of how much they are being used.\n",
    "\n",
    "However, we can use this information later in conjunction with other data in both datasets to find out the apps that are most used by the users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# App Profile Recommendation from Apple Store\n",
    "\n",
    "### Part One\n",
    "\n",
    "The frequency tables we analyzed on the previous screen showed us that the App Store is dominated by apps designed for fun, while Google Play shows a more balanced landscape of both practical and fun apps. Now, we'd like to get an idea about the kind of apps with the most users.\n",
    "\n",
    "One way to find out what genres are the most popular (have the most users) is to calculate the average number of `installs` for each app genre. For the Google Play data set, we can find this information in the Installs column, but this information is missing for the App Store data set. As a workaround, we'll take the total number of user ratings as a proxy, which we can find in the `rating_count_tot` column; this is the index `5` for each row in the Apple Store dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part Two\n",
    "\n",
    "Let's start with calculating the average number of user ratings per app genre on the App Store. To do that, we'll need to:\n",
    "- Isolate the apps of each genre.\n",
    "- Sum up the user ratings for the apps of that genre.\n",
    "- Divide the sum by the number of apps belonging to that genre (not by the total number of apps).\n",
    "\n",
    "We can start by generating a frequency table for the `'prime_genre'` column to get the unique app genres (below, we'll need to loop over the unique genres). We'll use the `freq_table()` function to do this.\n",
    "\n",
    "We can create a dictionary `freq_tbl_unique_prime_genre` for each unique app genre as the key and the average number of total ratings (`rating_count_tot'`) it got for all the apps under said genre.\n",
    "\n",
    "We want to display the `freq_tbl_unique_prime_genre` dictionary data in sorted (descending) manner. We use `sorted()` built-in function here again. However, as stated earlier once, `sorted()` doesn't work properly on dictionaries. So, we convert the dictionary into a tuple of list and then using `sorted()` we can print the descending ordered sorted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_tbl_unique_prime_genre = freq_table(ios_free_clean, 11)\n",
    "\n",
    "for genre in freq_tbl_unique_prime_genre:\n",
    "    total = 0\n",
    "    len_genre = 0\n",
    "    for each_row in ios_free_clean:\n",
    "        genre_app = each_row[11]\n",
    "        if genre_app == genre:\n",
    "            total += float(each_row[5]) #index 5 for column 'rating_count_tot'\n",
    "            len_genre += 1\n",
    "    avg = round(total/len_genre, 2)\n",
    "    freq_tbl_unique_prime_genre[genre] = avg\n",
    "\n",
    "table = freq_tbl_unique_prime_genre\n",
    "table_display = []\n",
    "for key in table:\n",
    "    key_val_as_tuple = (table[key], key)\n",
    "    table_display.append(key_val_as_tuple)\n",
    "\n",
    "table_sorted = sorted(table_display, reverse = True)\n",
    "for entry in table_sorted:\n",
    "    print(entry[1] + ': ' + str(entry[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the data above we are going to analyze the *top 5* app profiles and find out how many of their apps deserve the developers' attention so that they can target those for in-app ad campaigns.\n",
    "\n",
    "Let us first create a function `appPopularityByGenre()` that will given the following information: \n",
    "- `dataset`\n",
    "- `nameColumn` (index of each row for the app name) \n",
    "- `genreColumn` (index of each row for the app genre name)\n",
    "- `n_install_column` (index of each row for number of installation data)\n",
    "- `genreName` (the name of the genre)\n",
    "\n",
    "will find out the apps and the percentage of installation number under that genre. \n",
    "\n",
    "The function will firstly, print out the total number of apps under a certain genre. Then it will also only print out the apps that have 5% or more number of installation under that genre. Because, we believe it is not attention worthy of the developer which app has less than 5% of total number of installation under its genre. This means there are other apps that the users use more under that genre and those are more attention worthy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appPopularityByGenre(dataset, nameColumn, genreColumn, n_install_column, genreName, androidDataset=False):\n",
    "    app = {}\n",
    "    total_n_install = 0;\n",
    "    for each_row in dataset:\n",
    "        name = each_row[nameColumn]\n",
    "        if each_row[genreColumn] == genreName:\n",
    "            if not(androidDataset):\n",
    "                app[name] = float(each_row[n_install_column])\n",
    "                total_n_install += float(each_row[n_install_column])\n",
    "            else:\n",
    "                n_install = each_row[n_install_column]\n",
    "                n_install = n_install.replace('+', '')\n",
    "                n_install = n_install.replace(',', '')\n",
    "                app[name] = float(n_install)\n",
    "                total_n_install += float(n_install)\n",
    "    \n",
    "    print(\"Total app count for '\" + genreName + \"' genre: \", len(app))\n",
    "    print(\"\\n\")\n",
    "    print(\"Popular apps under this genre ===> \")\n",
    "    for k in app:\n",
    "        app[k] = round((app[k]/total_n_install) * 100, 2)\n",
    "        if app[k] >= 5:\n",
    "            print(k, \": \", app[k], \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have decided to analyze to *top 5* popular genre in apps in Apple Store. They are:\n",
    "1. Nvaigation\n",
    "2. Reference\n",
    "3. Social Networking\n",
    "4. Weather\n",
    "5. Music\n",
    "\n",
    "One by one, we are going to analyze each of these genre and will only print out the apps that are worthy of the developers' attention for increasing in-app ads and user engagement.\n",
    "\n",
    "We will start with the most popular one: **1. Navigation**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appPopularityByGenre(ios_free_clean, 1, 11, 5, 'Navigation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will take a look at **2. Reference**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appPopularityByGenre(ios_free_clean, 1, 11, 5, 'Reference')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's turn for **3. Social Networking**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appPopularityByGenre(ios_free_clean, 1, 11, 5, 'Social Networking')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we have **4. Music**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appPopularityByGenre(ios_free_clean, 1, 11, 5, 'Music')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have **5. Weather**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appPopularityByGenre(ios_free_clean, 1, 11, 5, 'Weather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# App Profile Recommendation from Google Playstore\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "freq_tbl_unique_genre = freq_table(android_free_clean, 9)\n",
    "\n",
    "for genre in freq_tbl_unique_genre:\n",
    "    total = 0\n",
    "    len_genre = 0\n",
    "    for each_row in android_free_clean:\n",
    "        genre_app = each_row[9]\n",
    "        if genre_app == genre:\n",
    "            n_installs = each_row[5] #index 5 for column 'installs'\n",
    "            n_installs = n_installs.replace('+', '')\n",
    "            n_installs = n_installs.replace(',', '')\n",
    "            total += float(n_installs) \n",
    "            len_genre += 1\n",
    "    avg = round(total/len_genre, 2)\n",
    "    freq_tbl_unique_genre[genre] = avg\n",
    "\n",
    "table = freq_tbl_unique_genre\n",
    "table_display = []\n",
    "for key in table:\n",
    "    key_val_as_tuple = (table[key], key)\n",
    "    table_display.append(key_val_as_tuple)\n",
    "\n",
    "table_sorted = sorted(table_display, reverse = True)\n",
    "for entry in table_sorted:\n",
    "    print(entry[1] + ': ' + str(entry[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Communication\n",
    "2. Adventure;Action & Adventure\n",
    "3. Video Players & Editors\n",
    "4. Social\n",
    "5. Arcade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appPopularityByGenre(android_free_clean, 0, 9, 5, 'Communication', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appPopularityByGenre(android_free_clean, 0, 9, 5, 'Adventure;Action & Adventure', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appPopularityByGenre(android_free_clean, 0, 9, 5, 'Video Players & Editors', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appPopularityByGenre(android_free_clean, 0, 9, 5, 'Social', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appPopularityByGenre(android_free_clean, 0, 9, 5, 'Arcade', True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
